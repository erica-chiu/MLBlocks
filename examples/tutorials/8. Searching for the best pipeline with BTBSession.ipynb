{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting and Tuning pipelines\n",
    "\n",
    "This guide shows you how to search for multiple pipelines for your problem\n",
    "and later on use a [BTBSession](https://hdi-project.github.io/BTB/api/btb.session.html#btb.session.BTBSession)\n",
    "to select and tune the best one.\n",
    "\n",
    "Note that some steps are not explained for simplicity. Full details\n",
    "about them can be found in the previous parts of the tutorial.\n",
    "\n",
    "Here we will:\n",
    "\n",
    "1. Load a dataset\n",
    "2. Search and load suitable templates\n",
    "3. Write a scoring function\n",
    "4. Build a BTBSession for our templates\n",
    "5. Run the session to find the best pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "The first step will be to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlprimitives.datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('census')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult Census dataset.\n",
      "\n",
      "    Predict whether income exceeds $50K/yr based on census data. Also known as \"Adult\" dataset.\n",
      "\n",
      "    Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean\n",
      "    records was extracted using the following conditions: ((AAGE>16) && (AGI>100) &&\n",
      "    (AFNLWGT>1)&& (HRSWK>0))\n",
      "\n",
      "    Prediction task is to determine whether a person makes over 50K a year.\n",
      "\n",
      "    source: \"UCI\n",
      "    sourceURI: \"https://archive.ics.uci.edu/ml/datasets/census+income\"\n",
      "    \n",
      "Data Modality: single_table\n",
      "Task Type: classification\n",
      "Task Subtype: binary\n",
      "Data shape: (32561, 14)\n",
      "Target shape: (32561,)\n",
      "Metric: accuracy_score\n",
      "Extras: \n"
     ]
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load suitable Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `mlblocks.discovery.find_pipelines` function to search\n",
    "for compatible pipelines.\n",
    "\n",
    "In this case, we will be looking for `single_table/classification` pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks.discovery import find_pipelines\n",
    "\n",
    "filters = {\n",
    "    'metadata.data_modality': 'single_table',\n",
    "    'metadata.task_type': 'classification'\n",
    "}\n",
    "templates = find_pipelines(filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['single_table.classification.categorical_encoder.logit',\n",
       " 'single_table.classification.categorical_encoder.random_forest',\n",
       " 'single_table.classification.categorical_encoder.xgboost',\n",
       " 'single_table.classification.mlprimitives.logit',\n",
       " 'single_table.classification.mlprimitives.random_forest',\n",
       " 'single_table.classification.mlprimitives.xgboost',\n",
       " 'single_table.classification.mlprimitives_text.xgboost']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we will create a dictionary with MLPipeline instances that will be used as tempaltes for our tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlblocks import MLPipeline\n",
    "\n",
    "templates_dict = {\n",
    "    template: MLPipeline(template)\n",
    "    for template in templates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlblocks.mlpipeline.MLPipeline at 0x7fd038c14e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates_dict['single_table.classification.mlprimitives.xgboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a scoring function\n",
    "\n",
    "In order to use a `BTBSession` we will need a function that is able to score a proposal,\n",
    "which will always be a pair of template name and proposed hyperparameters.\n",
    "\n",
    "In this case, the evaluation will be done using 5-fold cross validation over our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_validate(template_name, hyperparameters=None):\n",
    "    template = templates_dict[template_name]\n",
    "    scores = []\n",
    "    for X_train, X_test, y_train, y_test in dataset.get_splits(5):\n",
    "        pipeline = MLPipeline(template.to_dict())  # Make a copy of the template\n",
    "        if hyperparameters:\n",
    "            pipeline.set_hyperparameters(hyperparameters)\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        scores.append(dataset.score(y_test, y_pred))\n",
    "        \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the BTBSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create another dictionary with the tunable hyperparameters of each template.\n",
    "This will be used by the BTBSession to know how to tune each template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunables = {\n",
    "    name: template.get_tunable_hyperparameters(flat=True)\n",
    "    for name, template in templates_dict.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "  'max_labels'): {'type': 'int', 'default': 0, 'range': [0, 100]},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'lowercase'): {'type': 'bool', 'default': True},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'binary'): {'type': 'bool', 'default': True},\n",
       " ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "  'max_features'): {'type': 'int', 'default': 1000, 'range': [1, 10000]},\n",
       " ('sklearn.impute.SimpleImputer#1', 'strategy'): {'type': 'str',\n",
       "  'default': 'mean',\n",
       "  'values': ['mean', 'median', 'most_frequent', 'constant']},\n",
       " ('xgboost.XGBClassifier#1', 'n_estimators'): {'type': 'int',\n",
       "  'default': 100,\n",
       "  'range': [10, 1000]},\n",
       " ('xgboost.XGBClassifier#1', 'max_depth'): {'type': 'int',\n",
       "  'default': 3,\n",
       "  'range': [3, 10]},\n",
       " ('xgboost.XGBClassifier#1', 'learning_rate'): {'type': 'float',\n",
       "  'default': 0.1,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'gamma'): {'type': 'float',\n",
       "  'default': 0,\n",
       "  'range': [0, 1]},\n",
       " ('xgboost.XGBClassifier#1', 'min_child_weight'): {'type': 'int',\n",
       "  'default': 1,\n",
       "  'range': [1, 10]}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunables['single_table.classification.mlprimitives.xgboost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create a `BTBSession` instance passing them and the `cross_validate` function.\n",
    "\n",
    "We will also be setting it in `verbose` mode, so we can have a better insight on what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btb.session import BTBSession\n",
    "\n",
    "session = BTBSession(tunables, cross_validate, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After everything is set up, we can start running the tuning session passing it\n",
    "the number of iterations that we want to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9bb1cfdb2f48d4b6c8614ae1d357a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 20:16:01,059 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:16:01,060 - INFO - session - Obtaining default configuration for single_table.classification.categorical_encoder.logit\n",
      "2020-01-23 20:16:03,274 - INFO - session - New optimal found: single_table.classification.categorical_encoder.logit - 0.7975185708718643\n",
      "2020-01-23 20:16:03,284 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:16:03,285 - INFO - session - Obtaining default configuration for single_table.classification.categorical_encoder.random_forest\n",
      "2020-01-23 20:16:05,584 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:16:05,585 - INFO - session - Obtaining default configuration for single_table.classification.categorical_encoder.xgboost\n",
      "2020-01-23 20:16:10,613 - INFO - session - New optimal found: single_table.classification.categorical_encoder.xgboost - 0.8639171383183359\n",
      "2020-01-23 20:16:10,617 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:16:10,618 - INFO - session - Obtaining default configuration for single_table.classification.mlprimitives.logit\n",
      "2020-01-23 20:16:13,090 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:16:13,093 - INFO - session - Obtaining default configuration for single_table.classification.mlprimitives.random_forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '51a54054874dd7a83ff0e785ffdfee3b',\n",
       " 'name': 'single_table.classification.categorical_encoder.xgboost',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 0,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 100,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8639171383183359}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this loop, the BTBSession will build pipelines based on our templates and evaluate them\n",
    "using our scoring function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate results\n",
    "\n",
    "When the session funishes running it will return a the best proposal available and the\n",
    "obtained score.\n",
    "\n",
    "These results are also available as the `best_proposal` attribute from the btb session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '51a54054874dd7a83ff0e785ffdfee3b',\n",
       " 'name': 'single_table.classification.categorical_encoder.xgboost',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 0,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 100,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.1,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.0,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 1},\n",
       " 'score': 0.8639171383183359}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.best_proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feel that the score can still be improved and want to keep searching, we can simply run the session again which will continue tuning over the previous results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76ce44e1173496e99baaf7ee39a3df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 20:17:59,163 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:17:59,163 - INFO - session - Obtaining default configuration for single_table.classification.mlprimitives.xgboost\n",
      "2020-01-23 20:18:04,640 - INFO - session - Creating Tunable instance from dict.\n",
      "2020-01-23 20:18:04,640 - INFO - session - Obtaining default configuration for single_table.classification.mlprimitives_text.xgboost\n",
      "2020-01-23 20:18:04,779 - ERROR - mlpipeline - Exception caught producing MLBlock mlprimitives.custom.text.TextCleaner#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2657, in get_loc\n",
      "    return self._engine.get_loc(key)\n",
      "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 635, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 322, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/home/xals/Projects/MIT/MLPrimitives/mlprimitives/custom/text.py\", line 111, in produce\n",
      "    texts = X[self.column]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/frame.py\", line 2927, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2659, in get_loc\n",
      "    return self._engine.get_loc(self._maybe_cast_indexer(key))\n",
      "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "2020-01-23 20:18:04,799 - ERROR - session - Proposal 7 - single_table.classification.mlprimitives_text.xgboost crashed with the following configuration: ('mlprimitives.custom.text.TextCleaner#1', 'lower'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'accents'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'stopwords'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'non_alpha'): True\n",
      "('mlprimitives.custom.text.TextCleaner#1', 'single_chars'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'lowercase'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'binary'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'max_features'): 1000\n",
      "('sklearn.impute.SimpleImputer#1', 'strategy'): mean\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): gini\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_weight_fraction_leaf'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True\n",
      "('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2657, in get_loc\n",
      "    return self._engine.get_loc(key)\n",
      "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/btb/session.py\", line 272, in run\n",
      "    score = self.scorer(tunable_name, config)\n",
      "  File \"<ipython-input-7-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 722, in fit\n",
      "    self._produce_block(block, block_name, context, output_variables, outputs)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 635, in _produce_block\n",
      "    block_outputs = block.produce(**produce_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 322, in produce\n",
      "    return getattr(self.instance, self.produce_method)(**produce_kwargs)\n",
      "  File \"/home/xals/Projects/MIT/MLPrimitives/mlprimitives/custom/text.py\", line 111, in produce\n",
      "    texts = X[self.column]\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/frame.py\", line 2927, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2659, in get_loc\n",
      "    return self._engine.get_loc(self._maybe_cast_indexer(key))\n",
      "  File \"pandas/_libs/index.pyx\", line 108, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 132, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1601, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1608, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: 'text'\n",
      "2020-01-23 20:18:04,801 - WARNING - session - Too many errors: 1. Removing tunable single_table.classification.mlprimitives_text.xgboost\n",
      "2020-01-23 20:18:04,803 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.xgboost\n",
      "2020-01-23 20:18:22,026 - INFO - session - New optimal found: single_table.classification.categorical_encoder.xgboost - 0.8687079630193402\n",
      "2020-01-23 20:18:22,031 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.xgboost\n",
      "2020-01-23 20:19:13,106 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.logit\n",
      "2020-01-23 20:19:13,334 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.linear_model.LogisticRegression#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 302, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1280, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 447, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only l2 penalties, got l1 penalty.\n",
      "2020-01-23 20:19:13,339 - ERROR - session - Proposal 10 - single_table.classification.categorical_encoder.logit crashed with the following configuration: ('mlprimitives.custom.feature_extraction.CategoricalEncoder#1', 'max_labels'): 29\n",
      "('sklearn.impute.SimpleImputer#1', 'strategy'): constant\n",
      "('sklearn.linear_model.LogisticRegression#1', 'fit_intercept'): False\n",
      "('sklearn.linear_model.LogisticRegression#1', 'max_iter'): 71156\n",
      "('sklearn.linear_model.LogisticRegression#1', 'solver'): newton-cg\n",
      "('sklearn.linear_model.LogisticRegression#1', 'penalty'): l1\n",
      "('sklearn.linear_model.LogisticRegression#1', 'C'): 40.699406362214916\n",
      "('sklearn.linear_model.LogisticRegression#1', 'multi_class'): multinomial\n",
      "('sklearn.linear_model.LogisticRegression#1', 'intercept_scaling'): 933.5409791334005\n",
      "('sklearn.linear_model.LogisticRegression#1', 'tol'): 0.0017748534037681438\n",
      "('sklearn.linear_model.LogisticRegression#1', 'dual'): True\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/btb/session.py\", line 272, in run\n",
      "    score = self.scorer(tunable_name, config)\n",
      "  File \"<ipython-input-7-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 302, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1280, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 447, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only l2 penalties, got l1 penalty.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 20:19:13,340 - WARNING - session - Too many errors: 1. Removing tunable single_table.classification.categorical_encoder.logit\n",
      "2020-01-23 20:19:13,343 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.logit\n",
      "2020-01-23 20:19:26,076 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.random_forest\n",
      "2020-01-23 20:19:31,573 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.random_forest\n",
      "2020-01-23 20:19:34,763 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.xgboost\n",
      "2020-01-23 20:20:15,775 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.xgboost\n",
      "2020-01-23 20:21:49,655 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.logit\n",
      "2020-01-23 20:21:49,946 - ERROR - mlpipeline - Exception caught fitting MLBlock sklearn.linear_model.LogisticRegression#1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 302, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1280, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 447, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only l2 penalties, got l1 penalty.\n",
      "2020-01-23 20:21:49,948 - ERROR - session - Proposal 16 - single_table.classification.mlprimitives.logit crashed with the following configuration: ('mlprimitives.custom.feature_extraction.CategoricalEncoder#1', 'max_labels'): 97\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'lowercase'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'binary'): True\n",
      "('mlprimitives.custom.feature_extraction.StringVectorizer#1', 'max_features'): 4707\n",
      "('sklearn.impute.SimpleImputer#1', 'strategy'): constant\n",
      "('sklearn.linear_model.LogisticRegression#1', 'fit_intercept'): True\n",
      "('sklearn.linear_model.LogisticRegression#1', 'max_iter'): 26014\n",
      "('sklearn.linear_model.LogisticRegression#1', 'solver'): newton-cg\n",
      "('sklearn.linear_model.LogisticRegression#1', 'penalty'): l1\n",
      "('sklearn.linear_model.LogisticRegression#1', 'C'): 34.878827238511434\n",
      "('sklearn.linear_model.LogisticRegression#1', 'multi_class'): multinomial\n",
      "('sklearn.linear_model.LogisticRegression#1', 'intercept_scaling'): 406.1952335959628\n",
      "('sklearn.linear_model.LogisticRegression#1', 'tol'): 0.008653762646621075\n",
      "('sklearn.linear_model.LogisticRegression#1', 'dual'): True\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/btb/session.py\", line 272, in run\n",
      "    score = self.scorer(tunable_name, config)\n",
      "  File \"<ipython-input-7-067b925bbee5>\", line 11, in cross_validate\n",
      "    pipeline.fit(X_train, y_train)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 719, in fit\n",
      "    self._fit_block(block, block_name, context)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlpipeline.py\", line 619, in _fit_block\n",
      "    block.fit(**fit_args)\n",
      "  File \"/home/xals/Projects/MIT/MLBlocks/mlblocks/mlblock.py\", line 302, in fit\n",
      "    getattr(self.instance, self.fit_method)(**fit_kwargs)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 1280, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\", line 447, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver newton-cg supports only l2 penalties, got l1 penalty.\n",
      "2020-01-23 20:21:49,951 - WARNING - session - Too many errors: 1. Removing tunable single_table.classification.mlprimitives.logit\n",
      "2020-01-23 20:21:49,953 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.random_forest\n",
      "2020-01-23 20:22:23,153 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.random_forest\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/home/xals/.virtualenvs/MLBlocks/lib/python3.6/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "2020-01-23 20:22:24,832 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.xgboost\n",
      "2020-01-23 20:22:46,026 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.xgboost\n",
      "2020-01-23 20:22:53,670 - INFO - session - New optimal found: single_table.classification.mlprimitives.xgboost - 0.8739290413691612\n",
      "2020-01-23 20:22:53,677 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.random_forest\n",
      "2020-01-23 20:22:55,126 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.random_forest\n",
      "2020-01-23 20:23:10,345 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.xgboost\n",
      "2020-01-23 20:23:15,497 - INFO - session - Generating new proposal configuration for single_table.classification.mlprimitives.xgboost\n",
      "2020-01-23 20:23:28,746 - INFO - session - Generating new proposal configuration for single_table.classification.categorical_encoder.random_forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'd9854a57d48100da0f3584dc4490301f',\n",
       " 'name': 'single_table.classification.mlprimitives.xgboost',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 22,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'lowercase'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'binary'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'max_features'): 3863,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 193,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.29839198565184866,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.19826736959824165,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 4},\n",
       " 'score': 0.8739290413691612}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If you look at the logs you will notice how the BTBSession captures the errors that finds\n",
    "while executing the pipelines and automatically discards the failing tempaltes to be able to continue\n",
    "the tuning session without wasting time on them.\n",
    "\n",
    "The number of errors that we want to wait before discarding a template can be changed passing the\n",
    "`max_errors` argument to the `BTBSession` when it is build.\n",
    "\n",
    "Isn't it cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the best pipeline\n",
    "\n",
    "Once we are satisfied with the results, we can then build an instance of the best pipeline\n",
    "by reading the `best_proposal` attribute from the `session`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'd9854a57d48100da0f3584dc4490301f',\n",
       " 'name': 'single_table.classification.mlprimitives.xgboost',\n",
       " 'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "   'max_labels'): 22,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'lowercase'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'binary'): True,\n",
       "  ('mlprimitives.custom.feature_extraction.StringVectorizer#1',\n",
       "   'max_features'): 3863,\n",
       "  ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "  ('xgboost.XGBClassifier#1', 'n_estimators'): 193,\n",
       "  ('xgboost.XGBClassifier#1', 'max_depth'): 3,\n",
       "  ('xgboost.XGBClassifier#1', 'learning_rate'): 0.29839198565184866,\n",
       "  ('xgboost.XGBClassifier#1', 'gamma'): 0.19826736959824165,\n",
       "  ('xgboost.XGBClassifier#1', 'min_child_weight'): 4},\n",
       " 'score': 0.8739290413691612}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_proposal = session.best_proposal\n",
    "best_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = templates_dict[best_proposal['name']]\n",
    "\n",
    "pipeline = MLPipeline(template.to_dict())\n",
    "pipeline.set_hyperparameters(best_proposal['config'])\n",
    "\n",
    "pipeline.fit(dataset.data, dataset.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore other results\n",
    "\n",
    "Optionally, if we are interested in exploring the results of the previous proposals we can access them\n",
    "in the `trials` attribute of the `session` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '9dd9a11254f46b11ad42a12692b4965e',\n",
       "  'name': 'single_table.classification.categorical_encoder.logit',\n",
       "  'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "    'max_labels'): 0,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'fit_intercept'): True,\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'max_iter'): 100,\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'solver'): 'liblinear',\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'penalty'): 'l2',\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'C'): 1.0,\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'multi_class'): 'ovr',\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'intercept_scaling'): 1.0,\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'tol'): 0.0001,\n",
       "   ('sklearn.linear_model.LogisticRegression#1', 'dual'): False},\n",
       "  'score': 0.7975185708718643},\n",
       " {'id': 'f7ef0814341cee4f05280077b9b3de9c',\n",
       "  'name': 'single_table.classification.categorical_encoder.random_forest',\n",
       "  'config': {('mlprimitives.custom.feature_extraction.CategoricalEncoder#1',\n",
       "    'max_labels'): 0,\n",
       "   ('sklearn.impute.SimpleImputer#1', 'strategy'): 'mean',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'n_estimators'): 10,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'criterion'): 'gini',\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_features'): None,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_depth'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_split'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_samples_leaf'): 1,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1',\n",
       "    'min_weight_fraction_leaf'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'max_leaf_nodes'): 2,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'min_impurity_decrease'): 0.0,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'bootstrap'): True,\n",
       "   ('sklearn.ensemble.RandomForestClassifier#1', 'oob_score'): False},\n",
       "  'score': 0.7591904454179904}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(session.proposals.values())[0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
